{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9a3cf2-3dc8-4abf-b527-64881ca09ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "line 1\n",
      "line2\n",
      "abcdef\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b741d27-ccd8-4750-bb72-f639d9ea2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'this is data for new file'\n",
    "with open('new.txt', 'w+') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec58e181-ba07-4902-81e7-41e5bbbc19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = '\\nnew lines for new file'\n",
    "with open('new.txt', 'a') as f:\n",
    "    f.write(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d46ec4-888c-4b3b-af41-06b8882e5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is data for new file\n",
      "new lines for new file\n"
     ]
    }
   ],
   "source": [
    "with open('new.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02f9ad7-bdbf-40b1-9da1-33c037033943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gaura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\gaura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gaura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gaura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gaura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaura\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae973dff-d03e-4749-a960-b03dfa08bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ddceb1-9035-4050-a34b-76b435c3b5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan Mathison Turing (23 June 1912 to 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\n",
      "\n",
      "Born in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba method, an electromechanical machine that could find settings for the Enigma machine. He played a crucial role in cracking intercepted messages that enabled the Allies to defeat the Axis powers in many engagements, including the Battle of the Atlantic.\n",
      "\n",
      "After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. Turing wrote on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised during his lifetime because much of his work was covered by the Official Secrets Act.\n",
      "\n",
      "In 1952, Turing was prosecuted for homosexual acts. He accepted hormone treatment, a procedure commonly referred to as chemical castration, as an alternative to prison. Turing died on 7 June 1954, aged 41, from cyanide poisoning. An inquest determined his death as suicide, but the evidence is also consistent with accidental poisoning. Following a campaign in 2009, British prime minister Gordon Brown made an official public apology for \"the appalling way Turing was treated\". Queen Elizabeth II granted a pardon in 2013. The term \"Alan Turing law\" is used informally to refer to a 2017 law in the UK that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.\n",
      "\n",
      "Turing left an extensive legacy in mathematics and computing which today is recognised more widely, with statues and many things named after him, including an annual award for computing innovation. His portrait appears on the Bank of England 50 note, first released on 23 June 2021 to coincide with his birthday. The audience vote in a 2019 BBC series named Turing the greatest person of the 20th century.\n"
     ]
    }
   ],
   "source": [
    "# Practical 1 - Stop Word Removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stopword_removal(originalfile, newfile):\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    with open(originalfile) as f:\n",
    "        text = f.read()\n",
    "        data = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "        tokens = data.lower().split()\n",
    "    \n",
    "    with open (newfile, 'w') as f:\n",
    "        data = [token for token in tokens if token not in stopwords_set]\n",
    "        f.write(' '.join(data))\n",
    "\n",
    "stopword_removal('raw.txt', 'filtered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2128964b-cb00-4c17-87d8-51eb32d42647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alan', 1, 0, 0, 1, 0]\n",
      "['mathison', 1, 0, 0, 0, 0]\n",
      "['turing', 1, 1, 1, 1, 1]\n",
      "['23', 1, 0, 0, 0, 1]\n",
      "['june', 1, 0, 0, 1, 1]\n",
      "['1912', 1, 0, 0, 0, 0]\n",
      "['7', 1, 0, 0, 1, 0]\n",
      "['1954', 1, 0, 0, 1, 0]\n",
      "['english', 1, 0, 0, 0, 0]\n",
      "['mathematician', 1, 0, 0, 0, 0]\n",
      "['computer', 1, 0, 1, 0, 0]\n",
      "['scientist', 1, 0, 0, 0, 0]\n",
      "['logician', 1, 0, 0, 0, 0]\n",
      "['cryptanalyst', 1, 0, 0, 0, 0]\n",
      "['philosopher', 1, 0, 0, 0, 0]\n",
      "['theoretical', 1, 0, 0, 0, 0]\n",
      "['biologist', 1, 0, 0, 0, 0]\n",
      "['highly', 1, 0, 0, 0, 0]\n",
      "['influential', 1, 0, 0, 0, 0]\n",
      "['development', 1, 0, 0, 0, 0]\n",
      "['science', 1, 0, 0, 0, 0]\n",
      "['providing', 1, 0, 0, 0, 0]\n",
      "['formalisation', 1, 0, 0, 0, 0]\n",
      "['concepts', 1, 0, 0, 0, 0]\n",
      "['algorithm', 1, 0, 0, 0, 0]\n",
      "['computation', 1, 0, 0, 0, 0]\n",
      "['machine', 1, 1, 1, 0, 0]\n",
      "['considered', 1, 0, 0, 0, 0]\n",
      "['model', 1, 0, 0, 0, 0]\n",
      "['generalpurpose', 1, 0, 0, 0, 0]\n",
      "['widely', 1, 0, 0, 0, 1]\n",
      "['father', 1, 0, 0, 0, 0]\n",
      "['born', 0, 1, 0, 0, 0]\n",
      "['london', 0, 1, 0, 0, 0]\n",
      "['raised', 0, 1, 0, 0, 0]\n",
      "['southern', 0, 1, 0, 0, 0]\n",
      "['england', 0, 1, 0, 0, 1]\n",
      "['graduated', 0, 1, 0, 0, 0]\n",
      "['kings', 0, 1, 0, 0, 0]\n",
      "['college', 0, 1, 0, 0, 0]\n",
      "['cambridge', 0, 1, 0, 0, 0]\n",
      "['1938', 0, 1, 0, 0, 0]\n",
      "['earned', 0, 1, 0, 0, 0]\n",
      "['doctorate', 0, 1, 0, 0, 0]\n",
      "['degree', 0, 1, 0, 0, 0]\n",
      "['princeton', 0, 1, 0, 0, 0]\n",
      "['university', 0, 1, 1, 0, 0]\n",
      "['world', 0, 1, 0, 0, 0]\n",
      "['war', 0, 1, 1, 0, 0]\n",
      "['ii', 0, 1, 0, 1, 0]\n",
      "['worked', 0, 1, 1, 0, 0]\n",
      "['government', 0, 1, 0, 0, 0]\n",
      "['code', 0, 1, 0, 0, 0]\n",
      "['cypher', 0, 1, 0, 0, 0]\n",
      "['school', 0, 1, 0, 0, 0]\n",
      "['bletchley', 0, 1, 0, 0, 0]\n",
      "['park', 0, 1, 0, 0, 0]\n",
      "['britains', 0, 1, 0, 0, 0]\n",
      "['codebreaking', 0, 1, 0, 0, 0]\n",
      "['centre', 0, 1, 0, 0, 0]\n",
      "['produced', 0, 1, 0, 0, 0]\n",
      "['ultra', 0, 1, 0, 0, 0]\n",
      "['intelligence', 0, 1, 0, 0, 0]\n",
      "['led', 0, 1, 0, 0, 0]\n",
      "['hut', 0, 1, 0, 0, 0]\n",
      "['8', 0, 1, 0, 0, 0]\n",
      "['section', 0, 1, 0, 0, 0]\n",
      "['responsible', 0, 1, 0, 0, 0]\n",
      "['german', 0, 1, 0, 0, 0]\n",
      "['naval', 0, 1, 0, 0, 0]\n",
      "['cryptanalysis', 0, 1, 0, 0, 0]\n",
      "['devised', 0, 1, 0, 0, 0]\n",
      "['techniques', 0, 1, 0, 0, 0]\n",
      "['speeding', 0, 1, 0, 0, 0]\n",
      "['breaking', 0, 1, 0, 0, 0]\n",
      "['ciphers', 0, 1, 0, 0, 0]\n",
      "['including', 0, 1, 0, 0, 1]\n",
      "['improvements', 0, 1, 0, 0, 0]\n",
      "['prewar', 0, 1, 0, 0, 0]\n",
      "['polish', 0, 1, 0, 0, 0]\n",
      "['bomba', 0, 1, 0, 0, 0]\n",
      "['method', 0, 1, 0, 0, 0]\n",
      "['electromechanical', 0, 1, 0, 0, 0]\n",
      "['could', 0, 1, 0, 0, 0]\n",
      "['find', 0, 1, 0, 0, 0]\n",
      "['settings', 0, 1, 0, 0, 0]\n",
      "['enigma', 0, 1, 0, 0, 0]\n",
      "['played', 0, 1, 0, 0, 0]\n",
      "['crucial', 0, 1, 0, 0, 0]\n",
      "['role', 0, 1, 0, 0, 0]\n",
      "['cracking', 0, 1, 0, 0, 0]\n",
      "['intercepted', 0, 1, 0, 0, 0]\n",
      "['messages', 0, 1, 0, 0, 0]\n",
      "['enabled', 0, 1, 0, 0, 0]\n",
      "['allies', 0, 1, 0, 0, 0]\n",
      "['defeat', 0, 1, 0, 0, 0]\n",
      "['axis', 0, 1, 0, 0, 0]\n",
      "['powers', 0, 1, 0, 0, 0]\n",
      "['many', 0, 1, 0, 0, 1]\n",
      "['engagements', 0, 1, 0, 0, 0]\n",
      "['battle', 0, 1, 0, 0, 0]\n",
      "['atlantic', 0, 1, 0, 0, 0]\n",
      "['national', 0, 0, 1, 0, 0]\n",
      "['physical', 0, 0, 1, 0, 0]\n",
      "['laboratory', 0, 0, 1, 0, 0]\n",
      "['designed', 0, 0, 1, 0, 0]\n",
      "['automatic', 0, 0, 1, 0, 0]\n",
      "['computing', 0, 0, 1, 0, 1]\n",
      "['engine', 0, 0, 1, 0, 0]\n",
      "['one', 0, 0, 1, 0, 0]\n",
      "['first', 0, 0, 1, 0, 1]\n",
      "['designs', 0, 0, 1, 0, 0]\n",
      "['storedprogram', 0, 0, 1, 0, 0]\n",
      "['1948', 0, 0, 1, 0, 0]\n",
      "['joined', 0, 0, 1, 0, 0]\n",
      "['max', 0, 0, 1, 0, 0]\n",
      "['newmans', 0, 0, 1, 0, 0]\n",
      "['victoria', 0, 0, 1, 0, 0]\n",
      "['manchester', 0, 0, 1, 0, 0]\n",
      "['helped', 0, 0, 1, 0, 0]\n",
      "['develop', 0, 0, 1, 0, 0]\n",
      "['computers', 0, 0, 1, 0, 0]\n",
      "['became', 0, 0, 1, 0, 0]\n",
      "['interested', 0, 0, 1, 0, 0]\n",
      "['mathematical', 0, 0, 1, 0, 0]\n",
      "['biology', 0, 0, 1, 0, 0]\n",
      "['wrote', 0, 0, 1, 0, 0]\n",
      "['chemical', 0, 0, 1, 1, 0]\n",
      "['basis', 0, 0, 1, 0, 0]\n",
      "['morphogenesis', 0, 0, 1, 0, 0]\n",
      "['predicted', 0, 0, 1, 0, 0]\n",
      "['oscillating', 0, 0, 1, 0, 0]\n",
      "['reactions', 0, 0, 1, 0, 0]\n",
      "['belousov', 0, 0, 1, 0, 0]\n",
      "['zhabotinsky', 0, 0, 1, 0, 0]\n",
      "['reaction', 0, 0, 1, 0, 0]\n",
      "['observed', 0, 0, 1, 0, 0]\n",
      "['1960s', 0, 0, 1, 0, 0]\n",
      "['despite', 0, 0, 1, 0, 0]\n",
      "['accomplishments', 0, 0, 1, 0, 0]\n",
      "['never', 0, 0, 1, 0, 0]\n",
      "['fully', 0, 0, 1, 0, 0]\n",
      "['recognised', 0, 0, 1, 0, 1]\n",
      "['lifetime', 0, 0, 1, 0, 0]\n",
      "['much', 0, 0, 1, 0, 0]\n",
      "['work', 0, 0, 1, 0, 0]\n",
      "['covered', 0, 0, 1, 0, 0]\n",
      "['official', 0, 0, 1, 1, 0]\n",
      "['secrets', 0, 0, 1, 0, 0]\n",
      "['act', 0, 0, 1, 0, 0]\n",
      "['1952', 0, 0, 0, 1, 0]\n",
      "['prosecuted', 0, 0, 0, 1, 0]\n",
      "['homosexual', 0, 0, 0, 1, 0]\n",
      "['acts', 0, 0, 0, 1, 0]\n",
      "['accepted', 0, 0, 0, 1, 0]\n",
      "['hormone', 0, 0, 0, 1, 0]\n",
      "['treatment', 0, 0, 0, 1, 0]\n",
      "['procedure', 0, 0, 0, 1, 0]\n",
      "['commonly', 0, 0, 0, 1, 0]\n",
      "['referred', 0, 0, 0, 1, 0]\n",
      "['castration', 0, 0, 0, 1, 0]\n",
      "['alternative', 0, 0, 0, 1, 0]\n",
      "['prison', 0, 0, 0, 1, 0]\n",
      "['died', 0, 0, 0, 1, 0]\n",
      "['aged', 0, 0, 0, 1, 0]\n",
      "['41', 0, 0, 0, 1, 0]\n",
      "['cyanide', 0, 0, 0, 1, 0]\n",
      "['poisoning', 0, 0, 0, 1, 0]\n",
      "['inquest', 0, 0, 0, 1, 0]\n",
      "['determined', 0, 0, 0, 1, 0]\n",
      "['death', 0, 0, 0, 1, 0]\n",
      "['suicide', 0, 0, 0, 1, 0]\n",
      "['evidence', 0, 0, 0, 1, 0]\n",
      "['also', 0, 0, 0, 1, 0]\n",
      "['consistent', 0, 0, 0, 1, 0]\n",
      "['accidental', 0, 0, 0, 1, 0]\n",
      "['following', 0, 0, 0, 1, 0]\n",
      "['campaign', 0, 0, 0, 1, 0]\n",
      "['2009', 0, 0, 0, 1, 0]\n",
      "['british', 0, 0, 0, 1, 0]\n",
      "['prime', 0, 0, 0, 1, 0]\n",
      "['minister', 0, 0, 0, 1, 0]\n",
      "['gordon', 0, 0, 0, 1, 0]\n",
      "['brown', 0, 0, 0, 1, 0]\n",
      "['made', 0, 0, 0, 1, 0]\n",
      "['public', 0, 0, 0, 1, 0]\n",
      "['apology', 0, 0, 0, 1, 0]\n",
      "['appalling', 0, 0, 0, 1, 0]\n",
      "['way', 0, 0, 0, 1, 0]\n",
      "['treated', 0, 0, 0, 1, 0]\n",
      "['queen', 0, 0, 0, 1, 0]\n",
      "['elizabeth', 0, 0, 0, 1, 0]\n",
      "['granted', 0, 0, 0, 1, 0]\n",
      "['pardon', 0, 0, 0, 1, 0]\n",
      "['2013', 0, 0, 0, 1, 0]\n",
      "['term', 0, 0, 0, 1, 0]\n",
      "['law', 0, 0, 0, 1, 0]\n",
      "['used', 0, 0, 0, 1, 0]\n",
      "['informally', 0, 0, 0, 1, 0]\n",
      "['refer', 0, 0, 0, 1, 0]\n",
      "['2017', 0, 0, 0, 1, 0]\n",
      "['uk', 0, 0, 0, 1, 0]\n",
      "['retroactively', 0, 0, 0, 1, 0]\n",
      "['pardoned', 0, 0, 0, 1, 0]\n",
      "['men', 0, 0, 0, 1, 0]\n",
      "['cautioned', 0, 0, 0, 1, 0]\n",
      "['convicted', 0, 0, 0, 1, 0]\n",
      "['historical', 0, 0, 0, 1, 0]\n",
      "['legislation', 0, 0, 0, 1, 0]\n",
      "['outlawed', 0, 0, 0, 1, 0]\n",
      "['left', 0, 0, 0, 0, 1]\n",
      "['extensive', 0, 0, 0, 0, 1]\n",
      "['legacy', 0, 0, 0, 0, 1]\n",
      "['mathematics', 0, 0, 0, 0, 1]\n",
      "['today', 0, 0, 0, 0, 1]\n",
      "['statues', 0, 0, 0, 0, 1]\n",
      "['things', 0, 0, 0, 0, 1]\n",
      "['named', 0, 0, 0, 0, 1]\n",
      "['annual', 0, 0, 0, 0, 1]\n",
      "['award', 0, 0, 0, 0, 1]\n",
      "['innovation', 0, 0, 0, 0, 1]\n",
      "['portrait', 0, 0, 0, 0, 1]\n",
      "['appears', 0, 0, 0, 0, 1]\n",
      "['bank', 0, 0, 0, 0, 1]\n",
      "['50', 0, 0, 0, 0, 1]\n",
      "['note', 0, 0, 0, 0, 1]\n",
      "['released', 0, 0, 0, 0, 1]\n",
      "['2021', 0, 0, 0, 0, 1]\n",
      "['coincide', 0, 0, 0, 0, 1]\n",
      "['birthday', 0, 0, 0, 0, 1]\n",
      "['audience', 0, 0, 0, 0, 1]\n",
      "['vote', 0, 0, 0, 0, 1]\n",
      "['2019', 0, 0, 0, 0, 1]\n",
      "['bbc', 0, 0, 0, 0, 1]\n",
      "['series', 0, 0, 0, 0, 1]\n",
      "['greatest', 0, 0, 0, 0, 1]\n",
      "['person', 0, 0, 0, 0, 1]\n",
      "['20th', 0, 0, 0, 0, 1]\n",
      "['century', 0, 0, 0, 0, 1]\n",
      "Query: turing OR hello AND computer\n",
      "Result: [1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Practical 2 - Incidence Matrix and Evaluation of AND/OR query\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stopword_removal(originalfile, newfile):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(originalfile) as f:\n",
    "        text = f.read()\n",
    "        data = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "        tokens = data.lower().split()\n",
    "    \n",
    "    with open (newfile, 'w') as f:\n",
    "        data = [token for token in tokens if token not in stop_words]\n",
    "        f.write(' '.join(data))\n",
    "\n",
    "def incidence_matrix(n):\n",
    "    global positions\n",
    "    matrix = []\n",
    "    words = []\n",
    "    text = []\n",
    "    seen = set()\n",
    "    for i in range(1, 6):\n",
    "        new_file = f\"filtered{i}.txt\"\n",
    "        stopword_removal(f\"raw{i}.txt\", new_file)\n",
    "        \n",
    "        with open(new_file, 'r') as f:\n",
    "            data = f.read().split()\n",
    "            text.append(data)\n",
    "            for word in data:\n",
    "                if word not in seen: words.append(word)\n",
    "                seen.add(word)\n",
    "\n",
    "    row = 0\n",
    "    for word in words:\n",
    "        frequency = []\n",
    "        for i in range(5):\n",
    "            frequency.append(1 if word in text[i] else 0)\n",
    "        matrix.append([word] + frequency)\n",
    "        positions[word] = row\n",
    "        row += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def search(query, matrix):\n",
    "    global positions\n",
    "    n = len(matrix[0]) - 1 # minus one as first element is word\n",
    "    \n",
    "    terms = query.split()[0::2]\n",
    "    operators = query.split()[1::2]\n",
    "    \n",
    "    rows = []\n",
    "    for term in terms:\n",
    "        rownumber = positions.get(term)\n",
    "        if rownumber is None: rows.append([0 for _ in range(n)])\n",
    "        if rownumber is not None: rows.append(matrix[rownumber][1:])\n",
    "    \n",
    "    result = rows[0]\n",
    "    if len(rows) == 1: return result \n",
    "\n",
    "    current = 0\n",
    "    for row in rows[1:]:\n",
    "        for i in range(n):\n",
    "            if operators[current] == \"AND\": result[i] &= row[i]\n",
    "            if operators[current] == \"OR\": result[i] |= row[i]\n",
    "        if current < len(operators) - 1: current += 1\n",
    "    return result\n",
    "\n",
    "positions = {}\n",
    "matrix = incidence_matrix(5)\n",
    "query = \"turing OR hello AND computer\"\n",
    "result = search(query, matrix)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7131d-97d9-47ca-843b-81e377c36a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
